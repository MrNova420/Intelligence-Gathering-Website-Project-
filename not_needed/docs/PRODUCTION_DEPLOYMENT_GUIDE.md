# üöÄ Production Deployment Guide - Intelligence Gathering Platform

## **Complete Guide for Public Web Release**

This comprehensive guide covers deploying the Intelligence Gathering Platform to production web hosting for public access, with multiple provider options and deployment strategies.

---

## üåê **Deployment Options Overview**

### **üèÜ Recommended Providers by Use Case**

| Use Case | Provider | Cost | Complexity | Best For |
|----------|----------|------|------------|----------|
| **Quick Launch** | Vercel/Netlify | Free-$20/mo | ‚≠ê | Startups, MVP |
| **Full Control** | DigitalOcean | $12-50/mo | ‚≠ê‚≠ê | Small-Medium Business |
| **Enterprise** | AWS/Azure/GCP | $50-500+/mo | ‚≠ê‚≠ê‚≠ê | Large Scale |
| **Budget Friendly** | Heroku/Railway | $5-25/mo | ‚≠ê‚≠ê | Proof of Concept |
| **Self-Hosted** | VPS/Dedicated | $10-100+/mo | ‚≠ê‚≠ê‚≠ê | Maximum Control |

---

## üöÄ **Option 1: Quick Deploy (Vercel + Railway)**

**Best for**: Fast launch, automatic deployments, minimal configuration

### **Step 1: Deploy Backend (Railway)**

1. **Create Railway Account**: https://railway.app
2. **Deploy from GitHub**:
   ```bash
   # Connect your GitHub repository
   # Railway will auto-detect the backend
   ```

3. **Configure Environment Variables**:
   ```bash
   DATABASE_URL=postgresql://[Railway provides this]
   SECRET_KEY=[generate secure key]
   ENVIRONMENT=production
   FRONTEND_URL=https://your-app.vercel.app
   ```

4. **Deploy Configuration**:
   ```dockerfile
   # Railway uses our existing Dockerfile
   # Add to railway.json:
   {
     "build": {
       "builder": "dockerfile",
       "dockerfilePath": "backend/Dockerfile"
     },
     "deploy": {
       "startCommand": "python run_standalone.py"
     }
   }
   ```

### **Step 2: Deploy Frontend (Vercel)**

1. **Create Vercel Account**: https://vercel.com
2. **Import Project**: Connect your GitHub repo
3. **Configure Build**:
   ```json
   {
     "buildCommand": "cd frontend && npm run build",
     "outputDirectory": "frontend/dist",
     "framework": "react"
   }
   ```

4. **Environment Variables**:
   ```bash
   REACT_APP_API_URL=https://your-backend.railway.app
   REACT_APP_ENVIRONMENT=production
   ```

### **Step 3: Custom Domain (Optional)**
```bash
# In Vercel dashboard:
# 1. Go to project settings
# 2. Add custom domain: yourdomain.com
# 3. Configure DNS with your domain provider
```

**Total Setup Time**: 30 minutes  
**Monthly Cost**: $0-20  
**Scaling**: Automatic

---

## üèóÔ∏è **Option 2: DigitalOcean Droplet (Full Control)**

**Best for**: Full control, custom configuration, medium scale

### **Step 1: Create Droplet**

1. **Create DigitalOcean Account**: https://digitalocean.com
2. **Create Droplet**:
   - **Image**: Ubuntu 22.04 LTS
   - **Size**: Basic ($12/mo - 2GB RAM, 1 vCPU)
   - **Region**: Choose closest to your users
   - **Authentication**: SSH keys recommended

### **Step 2: Server Setup**

```bash
# Connect to your droplet
ssh root@your-droplet-ip

# Update system
apt update && apt upgrade -y

# Install dependencies
apt install nginx postgresql postgresql-contrib redis-server \
    python3 python3-pip nodejs npm git certbot python3-certbot-nginx -y

# Create application user
adduser --system --group intelligence
mkdir -p /var/www/intelligence
chown intelligence:intelligence /var/www/intelligence
```

### **Step 3: Deploy Application**

```bash
# Switch to app user
sudo -u intelligence -s

# Navigate to app directory
cd /var/www/intelligence

# Clone repository
git clone https://github.com/YourUsername/Intelligence-Gathering-Website-Project-.git .

# Install Python dependencies
pip3 install -r backend/requirements.txt

# Install Node.js dependencies
cd frontend && npm install && npm run build && cd ..

# Setup environment
cp .env.example .env
nano .env  # Configure production settings
```

### **Step 4: Database Setup**

```bash
# Create PostgreSQL database
sudo -u postgres psql
CREATE DATABASE intelligence_platform;
CREATE USER intelligence WITH ENCRYPTED PASSWORD 'secure_password';
GRANT ALL PRIVILEGES ON DATABASE intelligence_platform TO intelligence;
\q

# Setup database
cd /var/www/intelligence/backend
python app/db/setup_standalone.py
```

### **Step 5: Nginx Configuration**

```nginx
# /etc/nginx/sites-available/intelligence
server {
    listen 80;
    server_name yourdomain.com www.yourdomain.com;

    # Frontend
    location / {
        root /var/www/intelligence/frontend/dist;
        try_files $uri $uri/ /index.html;
        
        # Security headers
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header X-Content-Type-Options "nosniff" always;
    }

    # Backend API
    location /api/ {
        proxy_pass http://127.0.0.1:8000/;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # Static files
    location /static/ {
        alias /var/www/intelligence/backend/static/;
        expires 1y;
        add_header Cache-Control "public, immutable";
    }
}

# Enable site
sudo ln -s /etc/nginx/sites-available/intelligence /etc/nginx/sites-enabled/
sudo nginx -t
sudo systemctl restart nginx
```

### **Step 6: SSL Certificate**

```bash
# Get free SSL certificate from Let's Encrypt
sudo certbot --nginx -d yourdomain.com -d www.yourdomain.com

# Auto-renewal (already setup by certbot)
sudo systemctl status certbot.timer
```

### **Step 7: Process Management (Systemd)**

```bash
# Backend service
sudo tee /etc/systemd/system/intelligence-backend.service << EOF
[Unit]
Description=Intelligence Gathering Platform Backend
After=network.target postgresql.service redis.service

[Service]
Type=simple
User=intelligence
WorkingDirectory=/var/www/intelligence/backend
Environment=PATH=/var/www/intelligence/venv/bin
ExecStart=/usr/bin/python3 run_standalone.py
Restart=always
RestartSec=3

[Install]
WantedBy=multi-user.target
EOF

# Enable services
sudo systemctl daemon-reload
sudo systemctl enable intelligence-backend
sudo systemctl start intelligence-backend
sudo systemctl status intelligence-backend
```

**Total Setup Time**: 2-3 hours  
**Monthly Cost**: $12-50  
**Scaling**: Manual

---

## ‚òÅÔ∏è **Option 3: AWS Complete Setup**

**Best for**: Enterprise scale, global distribution, advanced features

### **Step 1: AWS Services Setup**

```bash
# Services we'll use:
# - EC2: Application servers
# - RDS: PostgreSQL database
# - ElastiCache: Redis
# - S3: Static files
# - CloudFront: CDN
# - Route 53: DNS
# - Certificate Manager: SSL
```

### **Step 2: Infrastructure Setup**

```bash
# Create VPC and subnets
aws ec2 create-vpc --cidr-block 10.0.0.0/16

# Create security groups
aws ec2 create-security-group \
  --group-name intelligence-web \
  --description "Intelligence Platform Web Servers"

# Launch RDS PostgreSQL
aws rds create-db-instance \
  --db-instance-identifier intelligence-db \
  --db-instance-class db.t3.micro \
  --engine postgres \
  --master-username intelligence \
  --master-user-password [secure-password] \
  --allocated-storage 20
```

### **Step 3: EC2 Instance Setup**

```bash
# Launch EC2 instance
aws ec2 run-instances \
  --image-id ami-0c02fb55956c7d316 \
  --instance-type t3.small \
  --key-name your-key-pair \
  --security-group-ids sg-xxxxxxxx

# Install application (similar to DigitalOcean steps)
# But configure for AWS services
```

### **Step 4: Load Balancer & Auto Scaling**

```bash
# Create Application Load Balancer
aws elbv2 create-load-balancer \
  --name intelligence-alb \
  --subnets subnet-xxxxxxxx subnet-yyyyyyyy

# Create Auto Scaling Group
aws autoscaling create-auto-scaling-group \
  --auto-scaling-group-name intelligence-asg \
  --min-size 2 \
  --max-size 10 \
  --desired-capacity 2
```

### **Step 5: CloudFront Distribution**

```bash
# Create CloudFront distribution for global CDN
aws cloudfront create-distribution \
  --distribution-config file://cloudfront-config.json
```

**Total Setup Time**: 4-6 hours  
**Monthly Cost**: $50-500+  
**Scaling**: Automatic, global

---

## üõ°Ô∏è **Security Configuration**

### **Essential Security Settings**

```bash
# 1. Environment Variables (Never commit secrets)
DATABASE_URL=postgresql://user:pass@host:5432/db
SECRET_KEY=[64-character random string]
JWT_SECRET=[64-character random string]
ENCRYPTION_KEY=[64-character random string]

# 2. Firewall Configuration
ufw allow ssh
ufw allow 'Nginx Full'
ufw enable

# 3. Database Security
# - Use connection pooling
# - Enable SSL connections
# - Regular backups
# - Limited user permissions

# 4. Application Security
# - Enable HTTPS only
# - Set security headers
# - Rate limiting
# - Input validation
# - SQL injection protection
```

### **Production Environment Variables**

```bash
# .env.production
NODE_ENV=production
ENVIRONMENT=production
DEBUG=false

# Database
DATABASE_URL=postgresql://user:password@host:5432/database
REDIS_URL=redis://host:6379/0

# Security
SECRET_KEY=your-64-character-secret-key
JWT_SECRET=your-jwt-secret-key
ENCRYPTION_KEY=your-encryption-key

# External Services
CLEARBIT_API_KEY=your-api-key
HUNTER_API_KEY=your-api-key
STRIPE_SECRET_KEY=your-stripe-key

# URLs
FRONTEND_URL=https://yourdomain.com
BACKEND_URL=https://api.yourdomain.com

# Email (if using)
SMTP_HOST=smtp.yourdomain.com
SMTP_PORT=587
SMTP_USER=noreply@yourdomain.com
SMTP_PASS=your-email-password
```

---

## üìä **Monitoring & Analytics**

### **Application Monitoring**

```bash
# 1. Add monitoring endpoints
# /health - Basic health check
# /metrics - Application metrics
# /status - Detailed status

# 2. Setup external monitoring
# - UptimeRobot (free)
# - Pingdom ($15/mo)
# - New Relic ($25+/mo)
# - DataDog ($15+/mo)
```

### **Performance Monitoring**

```python
# Add to backend/app/main.py
import sentry_sdk
from sentry_sdk.integrations.fastapi import FastApiIntegration

sentry_sdk.init(
    dsn="your-sentry-dsn",
    integrations=[FastApiIntegration()],
    traces_sample_rate=1.0,
)
```

### **Analytics Integration**

```html
<!-- Add to frontend/public/index.html -->
<!-- Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=GA_TRACKING_ID"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'GA_TRACKING_ID');
</script>
```

---

## üîÑ **CI/CD Pipeline**

### **GitHub Actions Deployment**

```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Deploy to DigitalOcean
        uses: appleboy/ssh-action@v0.1.5
        with:
          host: ${{ secrets.HOST }}
          username: ${{ secrets.USERNAME }}
          key: ${{ secrets.SSH_KEY }}
          script: |
            cd /var/www/intelligence
            git pull origin main
            pip install -r backend/requirements.txt
            cd frontend && npm install && npm run build
            sudo systemctl restart intelligence-backend
            sudo systemctl reload nginx
```

### **Automated Backups**

```bash
# Daily database backup script
#!/bin/bash
# /etc/cron.daily/intelligence-backup

DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/var/backups/intelligence"
DB_NAME="intelligence_platform"

# Create backup directory
mkdir -p $BACKUP_DIR

# Backup database
pg_dump $DB_NAME > $BACKUP_DIR/db_backup_$DATE.sql

# Backup files
tar -czf $BACKUP_DIR/files_backup_$DATE.tar.gz /var/www/intelligence

# Upload to S3 (optional)
aws s3 cp $BACKUP_DIR/db_backup_$DATE.sql s3://your-backup-bucket/
aws s3 cp $BACKUP_DIR/files_backup_$DATE.tar.gz s3://your-backup-bucket/

# Clean old backups (keep 30 days)
find $BACKUP_DIR -type f -mtime +30 -delete
```

---

## üåç **Domain & DNS Configuration**

### **Domain Setup Steps**

1. **Purchase Domain**: Namecheap, GoDaddy, Cloudflare
2. **Configure DNS Records**:
   ```
   A     @           your-server-ip
   A     www         your-server-ip
   CNAME api         your-backend-url
   TXT   @           "v=spf1 include:yourdomain.com ~all"
   ```

3. **SSL Certificate**: Let's Encrypt (free) or CloudFlare (free)

### **CDN Setup (CloudFlare)**

```bash
# 1. Add site to CloudFlare
# 2. Update nameservers at domain registrar
# 3. Configure SSL/TLS: Full (strict)
# 4. Enable security features:
#    - DDoS protection
#    - WAF rules
#    - Rate limiting
```

---

## üí∞ **Cost Breakdown & Scaling**

### **Startup Costs (Monthly)**

| Provider | Basic Setup | Medium Scale | Enterprise |
|----------|-------------|--------------|------------|
| **Vercel + Railway** | $0-20 | $50-100 | $200+ |
| **DigitalOcean** | $12-25 | $50-150 | $300+ |
| **AWS** | $50-100 | $200-500 | $1000+ |
| **Self-Hosted** | $10-30 | $100-300 | $500+ |

### **Scaling Thresholds**

```bash
# When to scale up:
# - Response time > 2 seconds consistently
# - Server CPU > 80% for 5+ minutes
# - Memory usage > 90%
# - Database connections > 80% of max
# - Error rate > 1%

# Scaling strategies:
# 1. Vertical: Increase server size
# 2. Horizontal: Add more servers
# 3. Database: Read replicas, sharding
# 4. CDN: Cache static content
# 5. Load balancing: Distribute traffic
```

---

## üö® **Troubleshooting Production Issues**

### **Common Issues & Solutions**

| Issue | Symptom | Solution |
|-------|---------|----------|
| **High Memory** | Server crashes | Add swap, optimize queries |
| **Slow Database** | Timeouts | Add indexes, query optimization |
| **SSL Errors** | Certificate warnings | Renew certificates |
| **High CPU** | Slow responses | Scale up/out, optimize code |
| **Disk Full** | Can't write files | Clean logs, add storage |

### **Emergency Procedures**

```bash
# 1. Quick server restart
sudo systemctl restart intelligence-backend
sudo systemctl restart nginx

# 2. Database issues
sudo systemctl status postgresql
sudo -u postgres psql -c "SELECT * FROM pg_stat_activity;"

# 3. Check logs
tail -f /var/log/nginx/error.log
journalctl -u intelligence-backend -f

# 4. Resource monitoring
htop
df -h
free -h
```

---

## üìã **Pre-Launch Checklist**

### **‚úÖ Technical Requirements**

- [ ] Domain purchased and configured
- [ ] SSL certificate installed and working
- [ ] Database optimized with indexes
- [ ] Backups configured and tested
- [ ] Monitoring and alerting setup
- [ ] Error tracking configured
- [ ] Performance testing completed
- [ ] Security audit performed

### **‚úÖ Legal & Compliance**

- [ ] Privacy Policy created
- [ ] Terms of Service written
- [ ] GDPR compliance (if EU users)
- [ ] Cookie policy implemented
- [ ] Data retention policy defined
- [ ] Security incident response plan

### **‚úÖ Business Readiness**

- [ ] Payment processing setup (if applicable)
- [ ] Customer support system ready
- [ ] Documentation complete
- [ ] User onboarding flow tested
- [ ] Marketing site ready
- [ ] Analytics tracking configured

---

## üéØ **Go-Live Steps**

### **Final Deployment Process**

```bash
# 1. Final testing in staging
./health_check.sh  # Should show 100% health

# 2. Database migration (if needed)
python backend/manage.py migrate

# 3. Deploy to production
git push origin main  # Triggers CI/CD

# 4. DNS cutover (if changing providers)
# Update DNS records with new IP

# 5. Monitor for 24 hours
# Check logs, performance, errors

# 6. Announce launch! üéâ
```

### **Post-Launch Monitoring**

```bash
# Monitor these metrics for first 48 hours:
# - Response times (< 2 seconds)
# - Error rates (< 1%)
# - Server resources (< 80% usage)
# - Database performance
# - User feedback and support tickets
```

---

## üéâ **Congratulations!**

Your Intelligence Gathering Platform is now live on the web! 

**Next Steps:**
- Monitor performance and user feedback
- Implement user-requested features
- Scale based on usage patterns
- Continue security updates and maintenance

**Need Help?** Check our troubleshooting guides or reach out to the community for support.